# Substreams ClickHouse Sink CLI

`substreams-sink-clickhouse` is a tool to pipe in data from the blockchain into a ClickHouse database.

## [Pre-built binaries](https://github.com/pinax-network/substreams-sink-clickhouse/releases)

- Linux

## Features

- TO-DO: See [issues](https://github.com/pinax-network/substreams-sink-clickhouse/issues?q=is%3Aissue+is%3Aclosed)

## Usage

Swagger Docs available on [http://localhost:3000](http://localhost:3000).

```bash
substreams-sink-clickhouse --help

Substreams Clickhouse sink module

Options:
  -V, --version                 output the version number
  -p, --port <number>           HTTP port on which to attach the sink (default: "3000", env: PORT)
  -v, --verbose <boolean>       Enable verbose logging (choices: "true", "false", default: "pretty", env: VERBOSE)
  -s, --schema-url <string>     Execute SQL instructions before starting the sink (env: SCHEMA_URL)
  --public-key <string>         Public key to validate messages (env: PUBLIC_KEY)
  --auth-key <string>           Auth key to validate requests (env: AUTH_KEY)
  --host <string>               Database HTTP hostname (default: "http://localhost:8123", env: HOST)
  --database <string>           The database to use inside ClickHouse (default: "default", env: DATABASE)
  --username <string>           Database user (default: "default", env: USERNAME)
  --password <string>           Password associated with the specified username (default: "", env: PASSWORD)
  --create-database <boolean    If the specified database does not exist, automatically create it (default: "false", env: CREATE_DATABASE)
  --async-insert <number>       https://clickhouse.com/docs/en/operations/settings/settings#async-insert (choices: "0", "1", default: 1, env: ASYNC_INSERT)
  --wait-for-insert <boolean>   https://clickhouse.com/docs/en/operations/settings/settings#wait-for-async-insert (choices: "0", "1", default: 0, env: WAIT_FOR_INSERT)
  --queue-limit <number>        Insert delay to each response when the pqueue exceeds this value (default: 10, env: QUEUE_LIMIT)
  --queue-concurrency <number>  https://github.com/sindresorhus/p-queue#concurrency (default: 10, env: QUEUE_CONCURRENCY)
  -h, --help                    display help for command
```

### Environment variables

**.env**

```bash
# Authentication
PUBLIC_KEY=... # Ed25519 Public-key provided by https://github.com/pinax-network/substreams-sink-webhook
AUTH_KEY=... # /schema endpoint is a protected endpoint (uses HTTP Basic authentication)

# Clickhouse Database
HOST=http://127.0.0.1:8123
DATABASE=default
USERNAME=default
PASSWORD=
CREATE_DB=false

# Sink
QUEUE_LIMIT=10
QUEUE_CONCURRENCY=10
SCHEMA_URL=... # generate SQL schema by providing file (ex: ./schema.sql) or URL path (ex: https://example.com/schema.sql)
VERBOSE=true
```

## Database structure

The `USER_DIMENSION` is generated by the user provided schema and is augmented by a few columns.

```mermaid
erDiagram
    USER_DIMENSION }|--|{ block : " "
    USER_DIMENSION }|--|{ manifest : " "

    block }|--|{ unparsed_json : " "
    manifest }|--|{ unparsed_json : " "

    USER_DIMENSION {
        user_data unknown
        id String
        block_id FixedString(64)
        module_hash FixedString(40)
        chain LowCardinality(String)
    }

    unparsed_json {
        raw_data JSON
        source LowCardinality(String)
        id String
        block_id FixedString(64)
        module_hash FixedString(40)
        chain LowCardinality(String)
    }

    block {
          block_id FixedString(64)
          block_number UInt32()
          chain LowCardinality(String)
          timestamp DateTime64(3_UTC)
          final_block   Bool
    }

    manifest {
        module_hash   FixedString(40)
        module_name   String()
        chain         LowCardinality(String)
        type          String()
    }
```

**Indexes**

| Table          | Fields                                     |
| -------------- | ------------------------------------------ |
| USER_DIMENSION | `(chain, module_hash)` `(chain, block_id)` |
| block          | `(block_id, block_number, timestamp)`      |
| manifest       | `module_hash`                              |

### Database initialization

Create a database in ClickHouse. (Optionally, skip this step and use the `default` database.)

```bash
substreams-sink-clickhouse --create-db --name <DB_NAME>
```

### Schema initialization

_This step can be skipped. If so, the data will be stored as-is in the `unparsed_json` table. It should then be parsed by the user with ClickHouse's tools (eg: `MaterializedView`)_

Initializes the database according to a SQL file. See [example file](#example-sql-file).

**CLI**

```
substreams-sink-clickhouse --schema-url <SCHEMA_URL>
```

**Web UI**

Upload a `.sql` file on [http://localhost:3000](http://localhost:3000). (POST request `/schema`, Content-Type: `application/octet-stream`)

**Curl**

```bash
curl --location --request POST 'http://localhost:3000/schema' --header 'Authorization: Bearer <AUTH_KEY>' --header 'Content-Type: application/json' --data-raw '<SQL_INSTRUCTIONS>'
```

#### Example SQL file

<details>
<summary>Click to expand</summary>

```sql
CREATE TABLE IF NOT EXISTS contracts (
    address  FixedString(40),
    name     String,
    symbol   String,
    decimals UInt8
)
ENGINE = ReplacingMergeTree
ORDER BY (address)
```

</details>

### Sink

Serves an endpoint to receive Substreams data from [substreams-sink-webhook](https://github.com/pinax-network/substreams-sink-webhook).

Endpoints are detailed on [http://localhost:3000](http://localhost:3000).

```bash
substreams-sink-clickhouse
# or
bun start
```
